[
  {
    "path": "posts/2025-02-05-kinase-bench-comprehensive-benchmarking-tool-for-improving-kinase-inhibitor-selectivity/",
    "title": "JCIM | Kinase-Bench：提高激酶抑制剂选择性的综合基准测试工具",
    "description": "激酶作为细胞信号通路的调节剂，在药物化学中一直是肿瘤学、免疫学和传染病最具吸引力的药物靶点。然而，激酶结构的高度相似性导致脱靶毒性，造成严重的不良药物反应。例如，泛 JAK 抑制剂因缺乏对其他 JAK 成员的选择性，导致心血管疾病、肿瘤和死亡风险。本研究旨在解决激酶选择性问题，采用虚拟筛选结合定制的蛋白 - 配体相互作用过滤器，对激酶选择性进行了广泛的基准研究。研究者利用严格的计算分析和验证实验，评估了该方法在识别选择性激酶抑制剂方面的有效性和可靠性。",
    "author": [
      {
        "name": "Jixing Liu",
        "url": "https://jixing475.github.io/jixingBlog"
      }
    ],
    "date": "2025-02-05",
    "categories": [
      "AIDD",
      "榴莲忘返 2014"
    ],
    "contents": "\n\nContents\n导读\n激酶虚拟筛选方法优化\n激酶虚拟筛选性能评估与增强\n总结\n\n\n\n\n\n\n导读\n激酶作为细胞信号通路的调节剂，在药物化学中一直是肿瘤学、免疫学和传染病最具吸引力的药物靶点。然而，激酶结构的高度相似性导致脱靶毒性，造成严重的不良药物反应。例如，泛 JAK 抑制剂因缺乏对其他 JAK 成员的选择性，导致心血管疾病、肿瘤和死亡风险。\n本研究旨在解决激酶选择性问题，采用虚拟筛选结合定制的蛋白 - 配体相互作用过滤器，对激酶选择性进行了广泛的基准研究。研究者利用严格的计算分析和验证实验，评估了该方法在识别选择性激酶抑制剂方面的有效性和可靠性。\n\n\n图 1. (A) 人类激酶组树，根据七个主要结构家族进行颜色编码，并标记了关键激酶受体。(B) 激酶图的示意图，显示了本研究中目标的选择性值。(C) ATP 结合位点 (85 个残基) 的序列比对显示了本研究中所有激酶的保守性和多样性。\n\n研究者检索了 322 种结构已被阐明和发表的激酶的所有已知配体活性数据。将具有亲和力和活性数据（来自 ChEMBL 数据库）的配体收集到单独的数据集中，并根据其选择性规则性能进行分离。所有 150 个数据集都系统地用于虚拟筛选方法，目的是理解和预测激酶选择性的分子基础。\n此外，研究者尝试通过结合经典的（基于能量的）方法和定制的过滤规则来提高虚拟筛选的选择性性能。研究的工作流程包括以下步骤： (A) 选择性受体对定义； (B) 配体和 VS 诱饵数据库准备； (C) 虚拟筛选； (D) 评估和增强虚拟筛选性能。\n\n\n图 2. 选择性激酶组基准虚拟筛选工作流程概述，包括 (A) 选择性受体对定义，(B) 配体数据库准备，(C) 虚拟筛选工作流程，以及 (D) 评估和增强虚拟筛选性能。\n\n\n\n图 3. (A) 基于生物活性信息的所有激酶选择性化合物的统计热图。(B) 组合配体数据库，由选择性配体（绿色）和相应的诱饵（红色）组成。\n\n通过系统地评估各种过滤器和筛选方案在不同激酶组中的性能，本研究希望阐明影响选择性的关键因素，并为合理设计激酶靶向疗法提供见解。最终，本研究致力于促进开发更安全、更有效的激酶抑制剂，从而改善各种疾病的治疗方法。\n激酶虚拟筛选方法优化\n研究者首先从 ChEMBL 数据库中检索了具有活性生物活性和结构信息的激酶抑制剂，并根据选择性定义了 150 个受体对和 75 个靶点。利用 DUD-E 在线工具生成了对应的 422,799 个诱饵分子。将选择性配体数据集和诱饵分子合并后，使用 RDKit 将其转换为三维 SDF 数据库，并计算了 Tanimoto 相似性、拓扑极性表面积 (TPSA)、氢键供体和氢键受体等分子理化性质。\n\n\n图 4. (A, B) 基于 RDKit 生成的 Morgan 指纹，八个激酶家族活性配体数据库的 Tanimoto 相似性、拓扑极性表面积 (TPSA) (A)、氢键供体和氢键受体 (B) 的散点图和密度曲线。(C) 代表性已上市药物（例如，Itacitinib (JAK1)、Quizartinib (FLT3) 等）和其他最相似 ChEMBL 分子的基于结构的相似性图，通过 Morgan 指纹计算。\n\n随后，研究者使用 LigPrep 模块对配体数据库进行处理，并使用 OPLS3 力场在 pH 7.4 ± 2 条件下进行离子化。从 PDB 数据库中获取了激酶晶体结构，并使用 Maestro 中的 Protein Preparation Wizard 模块进行预处理，包括添加氢原子和优化蛋白质能量状态。利用 Prime 程序填充缺失的环和侧链，并根据共晶配体在 ATP 结合口袋中手动设置一个 10Å的盒子作为结合位点。\n虚拟筛选模拟使用 Glide HTVS 进行，并使用对接分数、Glide Gscore 和 Glide Emodel 三种评分函数评估性能。此外，研究者基于 KLIFS 数据库和 PLIP 工具定义了定制的蛋白 - 配体相互作用过滤器。该过滤器考虑了七种不同类型的相互作用，并根据 150 个激酶的相互作用指纹 (IFP) 确定了 10 个关键的 KLIFS 残基位置。通过该过滤器，筛选出与这 10 个残基位置形成氢键或芳香相互作用的对接构象，并重新排序和计算富集因子。最后，通过激酶抑制实验和细胞生长抑制实验验证了筛选结果。\n研究者还进行了激酶抑制实验和细胞生长抑制实验，以验证虚拟筛选方法的有效性。实验结果表明，定制的蛋白 - 配体相互作用过滤器可以有效提高筛选的命中率和富集因子。\n图 5 展示了 150 个激酶及其共晶配体的相互作用指纹。\n\n图 5. 150 个激酶及其共晶配体的相互作用指纹 (IFPs)。残基根据其 85 个 KLIFS 编号进行着色。结构受体 - 配体相互作用模式由 KLIFS 中的 IFP 位串描述，编码七种不同的相互作用类型：疏水相互作用、芳香面面相互作用、芳香面边相互作用、氢键供体（受体）、氢键受体（受体）、离子正电（受体）和离子负电（受体）。配体与不同激酶氨基酸残基之间发生的这些相互作用主要以蓝色着色。根据 IFPs 下方的密度曲线，相互作用发生在>80% IFPs 的残基点以绿色着色（KLIFS Nr. 3、11、15、17、45-48、77 和 80)，并设置为我们的自定义过滤规则。\n激酶虚拟筛选性能评估与增强\n研究构建了一个开源激酶基准集，用于评估和改进激酶靶向选择性计算模型。研究者从 PDB 数据库中检索激酶靶标，并从 ChEMBL 数据库中获取配体及其生物活性信息（Ki, IC50, Kb, Kd 或 EC50）。使用 DUD-E 工具生成约 60 个计算诱饵，并采用 Glide HTVS 和 SP 对接协议及三种评分函数进行回顾性虚拟筛选。表 1 总结了基于三种评分函数的虚拟筛选结果（EF1%）。\n\n表 1. 回顾性虚拟筛选结果（EF1%）。\n结果显示，大多数选择性配体集在不同激酶家族中表现良好（EF1% > 20%），例如 ROCK1-GSK3B (50.0%) 和 ROCK2-AKT1 (51.9%)。然而，近一半的选择性配体集未产生理想的 Glide 对接构象和评分（EF1% < 20%）。尤其在 TK 家族中，三种评分函数和 Glide HTVS 对接程序中的结合构象均差于其他激酶家族（大多 EF1% < 20%）。\n\n图 6. (A) 基于 Docking Score, Glide Gscore 和 Glide Emodel 三个变量的主成分分析 (PCA) 得分图。(B) 基于三种能量评分函数的虚拟筛选性能总体 EF1%。\n\n主成分分析（PCA）表明，Docking Score 和 Glide Gscore 对 PC1 贡献最大，且性能相似，而 Glide Emodel 与 PC1 和 PC2 均相关，但不如前两者强。此外，Docking Score (中位数 EF1%: 16.52) 和 Glide Gscore (中位数 EF1%: 14.42) 的性能优于 Glide Emodel (中位数 EF1%: 6.34)。\n\n图 7. (A-C) 基于 Docking Score (A), Glide Gscore (B) 和 Glide Emodel (C) 的九个主要家族的 EF1% 雨云图。(D-G) 代表性配体和诱饵的对接构象及 2D 化学结构。\n\n通过对不同激酶家族的雨云图分析，研究者发现 Docking Score 的 EF1% 分布更广，表明预测结合亲和力的差异更大。然而，Docking Score 和 Glide Gscore 结果中的异常值表明，这些评分函数无法完全捕捉激酶 - 配体相互作用的每个独特方面。\n为了提高虚拟筛选的性能，特别是选择性，研究者开发了一个基于 KLIFS 残基相互作用的定制过滤器。结果表明，该过滤器显著提高了三种 Glide 评分函数的虚拟筛选性能（图 9）。\n\n图 9. (A) 基于三种 Glide 评分函数的定制蛋白 - 配体相互作用过滤器增强虚拟筛选的 3D 散点图。(B) 基于三种 Glide 评分函数的虚拟筛选总体命中率性能，有无定制的蛋白 - 配体相互作用过滤器。(C-E) 代表性配体和诱饵的对接构象及 2D 化学结构。\n\n进一步的分析表明，Nr. 17, Nr. 45, Nr. 46 和 Nr. 47 等位置的残基相互作用对提高选择性至关重要。此外，将对接协议从 HTVS 升级到 SP 也提高了虚拟筛选的性能，尤其是在选择性方面。体外药物验证实验表明，所选化合物对 JAK1 的抑制活性高于 TYK2，证实了该方法的有效性。最后，研究者还探讨了共价设计、别构抑制剂、伪激酶等策略在选择性虚拟筛选中的应用潜力，为未来的研究提供了方向。\n总结\n\nKinase-Bench 基准测试套件通过定制的虚拟筛选流程有效提升了激酶抑制剂的选择性和效力。\n\nKinase-Bench 基准测试套件助力选择性激酶抑制剂的发现。\n该套件整合了 ChEMBL 数据库的生物活性数据、DUD-E 生成的诱饵化合物以及定制的虚拟筛选流程。\n案例研究验证了该方法的有效性，并发现了具有 JAK1 选择性的潜在抑制剂。\n由于腺苷三磷酸 (ATP) 结合位点在激酶家族中的高度保守性，开发选择性激酶抑制剂仍然是药物发现中的一项巨大挑战。作者构建了名为”Kinase-Bench”的基准测试套件，旨在改进虚拟筛选流程，从而提高激酶抑制剂的选择性和效力。该套件包含针对 75 种激酶的 6875 个选择性配体和 422,799 个诱饵化合物，数据来源于 ChEMBL 数据库的广泛生物活性数据和 DUD-E（Directory of Useful Decoys-Enhanced）生成的诱饵化合物。研究者采用 Glide 高通量虚拟筛选和标准精度筛选，并结合三个评分函数和定制的蛋白 - 配体相互作用过滤器，以靶向特定的激酶残基相互作用。\n在针对 JAK1 抑制剂并使其对家族成员 TYK2 具有选择性的虚拟筛选工作中，这些创新得到了成功的应用。结果发现了新的潜在苗头化合物：化合物 2（JAK1 IC₅₀：980.5 nM，TYK2 IC₅₀：4.5 μM）和已获批的泛 AKT 抑制剂 Capivasertib（JAK1 IC₅₀：275.9 nM，TYK2 IC₅₀：10.9 μM）。使用 Kinase-Bench 协议，两种化合物均表现出显著的 JAK1 选择性，使其成为进一步研究的强有力候选物。这些结果强调了定制虚拟筛选协议在识别选择性激酶抑制剂方面的实用性，对合理药物设计具有重要意义。Kinase-Bench 为选择性激酶药物发现提供了一个强大的工具集，有潜力有效地指导未来的治疗策略。\n参考资料：\n\n\n标题：Kinase-Bench: Comprehensive Benchmarking Tools and Guidance for Achieving Selectivity in Kinase Drug Discovery \n\n\n\n\n作者：Wei, Tian-Hua; Zhou, Shuang-Shuang; Jing, Xiao-Long; Liu, Jia-Chuan; Sun, Meng; Zhao, Zong-Hao; Li, Qing-Qing; Wang, Zi-Xuan; Yang, Jin; Zhou, Yun; others \n\n\n\n\n期刊：J. Chem. Inf. Model. \n\n\n\n\nDOI: 10.1021/acs.jcim.4c01830 \n\n\n\n\n发表年份：2024 \n\n\n\n\n\n",
    "preview": "posts/2025-02-05-kinase-bench-comprehensive-benchmarking-tool-for-improving-kinase-inhibitor-selectivity/images/0194d46d-7ab1-7d73-8ab9-08185218be05_1_138_164_1494_1002_0.jpg",
    "last_modified": "2025-02-05T22:03:50+08:00",
    "input_file": {}
  },
  {
    "path": "posts/2024-04-09-using-active-learning-in-a-3d-similarity-search/",
    "title": "学习笔记: 在 3D 相似性搜索中使用主动学习",
    "description": "在药物发现中，使用主动学习来识别具有所需特性的分子非常有价值。本文演示了如何使用主动学习来查找具有与查询分子相似的形状和药效团特征的分子。我们使用高斯过程回归作为机器学习模型，并使用 Tanimoto 相似性作为核函数。我们还定义了几个获取函数，包括贪婪函数和最大化概率改进 (PI) 函数。我们使用来自 LitPCBA 数据集的分子进行了实验，结果表明主动学习优于随机选择。",
    "author": [
      {
        "name": "Jixing Liu",
        "url": "https://jixing475.github.io/jixingBlog"
      }
    ],
    "date": "2024-04-09",
    "categories": [
      "experimental design",
      "R"
    ],
    "contents": "\n\nContents\n安装必要的 Python 软件包\nOracle 定义\n定义高斯过程回归的核函数\n读取输入数据\n定义一些实用函数\n定义获取函数\n运行 Active Learning\n运行随机选择以与主动学习进行比较\n\n\n\n\n\n\n\n\nClick Me\n\nto see all code in this article.\n\n\n\n\n\n\n在本次教程中，我们将考虑一个完整的示例，其中我们使用主动学习来查找具有与查询分子相似的形状和药效团特征的分子。此笔记本中的一些代码和数据是从其他开源项目中借用的。非常感谢这些软件包的作者开源代码。\n查询和数据库分子取自 LitPCBA 集。\n3D 叠加代码来自 ESPSim\n一些代码也借鉴了 Lig3DLens\n参考教程\n安装必要的 Python 软件包\n导入我们需要的库。\n\n\nfrom operator import itemgetter\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport sklearn.gaussian_process as gp\nimport useful_rdkit_utils as uru\nfrom modAL.acquisition import BaseLearner\nfrom modAL.models import BayesianOptimizer\nfrom modAL.utils.data import modALinput\nfrom modAL.acquisition import optimizer_PI\nfrom rdkit import Chem\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom tqdm.auto import tqdm\nfrom modAL.utils.selection import multi_argmax\nfrom align3D_score import score_alignment\nfrom gen_conformers import generate_conformers\nimport py3Dmol\n\n\nOracle 定义\nOracle 是一个组件，它将查询分子与数据库中的分子进行比较，并根据它们的形状和药效团特征对它们进行评分。在本文中，我们使用自定义的 Oracle，该 Oracle 使用 ESPSim 库来计算分子之间的形状相似性，并使用 RDKit 来计算药效团相似性。Oracle 返回一个分数，该分数表示查询分子与数据库分子之间的相似性程度。\n\n\nclass ShapeOracle:\n    # instantiate the oracle with a query molecule\n    def __init__(self, ref_molfile):\n        \"\"\"\n        Initialize the oracle with a query molecule.\n\n        Args:\n            ref_molfile (str): The path to the query molecule file.\n        \"\"\"\n        self.ref_mol = Chem.MolFromMolFile(ref_molfile)\n        self.ref_mol = Chem.AddHs(self.ref_mol)\n\n    def get_values(self, input_smiles_list):\n        \"\"\"\n        Get the values for the input smiles list.\n\n        Args:\n            input_smiles_list (list): The list of SMILES strings.\n\n        Returns:\n            list: The list of values.\n        \"\"\"\n        result_list = []\n        for smi in tqdm(input_smiles_list):\n            res = None\n            mol = Chem.MolFromSmiles(smi)\n            if mol:\n                mol = Chem.AddHs(mol)\n                mol_3d = generate_conformers(mol, 25)\n                if mol_3d:\n                    res = score_alignment(mol_3d, self.ref_mol)\n            result_list.append(res)\n        return result_list\n\n\n定义高斯过程回归的核函数\n在高斯过程回归 (GPR) 中，核函数用于衡量数据点之间的相似性。在本文中，我们使用 Tanimoto 相似性作为核函数。Tanimoto 相似性是一种衡量两个集合相似性的度量，它计算两个集合中共有元素的数量与两个集合中元素总数之比。\n我们使用 Tanimoto 相似性作为核函数，因为它是衡量分子之间形状和药效团特征相似性的常用方法。通过使用 Tanimoto 相似性作为核函数，我们的 GPR 模型能够学习分子之间的相似性模式，并对新分子的相似性进行预测。\n\n\ndef calculate_similarity(a, b):\n    \"\"\"\n    Calculate the Tanimoto similarity between two sets of fingerprints.\n\n    Args:\n        a (np.array): The first set of fingerprints.\n        b (np.array): The second set of fingerprints.\n\n    Returns:\n        np.array: The Tanimoto similarity between the two sets of fingerprints.\n    \"\"\"\n    # Tanimoto similarity a vs. b\n    aa = np.sum(a, axis=1, keepdims=True)\n    bb = np.sum(b, axis=1, keepdims=True)\n    ab = np.matmul(a, b.T)\n    return np.true_divide(ab, aa + bb.T - ab)\n\n\nclass TanimotoKernel(gp.kernels.NormalizedKernelMixin,\n                     gp.kernels.StationaryKernelMixin, gp.kernels.Kernel):\n\n    def __init__(self):\n        pass\n\n    def __call__(self, X, Y=None, eval_gradient=False):\n        \"\"\"\n        Evaluate the Tanimoto kernel.\n\n        Args:\n            X (np.array): The first set of fingerprints.\n            Y (np.array, optional): The second set of fingerprints. If None, then Y = X.\n            eval_gradient (bool, optional): Whether to evaluate the gradient of the kernel.\n\n        Returns:\n            np.array: The Tanimoto similarity between the two sets of fingerprints.\n        \"\"\"\n        assert not eval_gradient\n        if Y is None:\n            Y = X\n        return calculate_similarity(X, Y)\n\n\n\n\ntqdm.pandas()\n\n\n读取输入数据\n我们从 LitPBCBA 数据集中读取输入数据。该数据集包含具有已知活性的分子。我们将使用此数据来训练我们的机器学习模型并评估其性能。\n\n\ndf = pd.read_csv(\"data/MAPK1.csv\")\n\n\n查看数据\n我们快速查看一下数据。在本例中，我们将忽略 activity 这一列。\n\n\ndf\n\n\n生成机器学习模型的描述符\n添加一个 fp 指纹列到数据框中。\n\n\ndf['fp'] = df.SMILES.progress_apply(uru.smi2numpy_fp)\n\n\n创建一个 X_pool (指纹池) 供主动学习算法从中提取。\n\n\nX_pool = np.stack(df.fp.values)\n\n\n定义一些实用函数\n对于贪婪搜索，我们希望选择得分最高的分子，但我们希望避免选择相同的分子多次。此函数接受预测列表并执行以下操作：\n按分数排序\n删除已选择的分子\n返回前 num_to_choose 个分子\n\n\ndef find_best_idx(predicted, used, num_to_choose):\n    tmp_list = list(enumerate(predicted))\n    tmp_list.sort(key=itemgetter(1), reverse=True)\n    tmp_list = [x for x in tmp_list if x[0] not in used]\n    tmp_list = [x[0] for x in tmp_list]\n    return tmp_list[:num_to_choose]\n\n\n将形状搜索结果与分子合并到数据框中的函数。\n\n\ndef compile_results(df_in, shape_results):\n    df_in['shape_res'] = shape_results\n    df_in.dropna(subset='shape_res',inplace=True)\n    df_in['score'] = [x.shape_score + x.esp_score + x.rdkit_score for x in df_in.shape_res]\n    return df_in\n\n\n定义获取函数\n这里有几个获取函数。\n第一个贪婪函数简单地选择n个由 oracle 评估的最高分分子。\n第二个my_max_PI函数最大化改进概率 (PI)，并使用不确定性和分数来平衡探索和利用。\n与论文“优化自由能计算的主动学习”相关联的 git 存储库包含其他几个获取函数的示例。从论文的工作中可以得出结论，获取函数不会产生巨大差异。\n\n\ndef greedy(optimizer: BaseLearner, X: modALinput, n_instances=1, used=[]):\n    res = optimizer.predict(X)\n    best_idx = find_best_idx(res, used, n_instances)\n    return best_idx, X[best_idx]\n\ndef my_max_PI(optimizer: BaseLearner, X: modALinput, tradeoff: float = 0,\n           n_instances: int = 1, used = [], cycle = -1) -> np.ndarray:\n    pi = optimizer_PI(optimizer, X, tradeoff=tradeoff)\n    best_idx = find_best_idx(pi, used, n_instances)\n    return best_idx, X[best_idx]\n\n\n运行 Active Learning\n创建将返回值的 Oracle。\n\n\noracle = ShapeOracle(\"data/2chw_lig.sdf\")\n\n\n这是主要的主动学习循环。我们将进行 3 个周期的主动学习。在 Colab 上，每个循环需要 1-2 分钟，在 M1 Mac 上，每个循环需要 10-20 秒。\n\n\n# number of molecules to select at each active learning cycle\nn_instances = 100\n# number of active learning cycles to run\nn_cycles = 3\n\n# define the acquistion function\nquery_strategy = my_max_PI\n\n# select an initial random sample\nsample_df = df.sample(n_instances).copy()\n\nsample_df['cycle'] = 0\n# get the shape scores for the random sample\ninit_shape_res = oracle.get_values(sample_df.SMILES.values)\n\n# add the scores to the dataframe\ndef compile_results(df_in, shape_results):\n    df_in['shape_res'] = shape_results\n    #df_in.dropna(subset='shape_res',inplace=True)\n    df_in['score'] = [x.shape_score + x.esp_score + x.rdkit_score for x in df_in.shape_res]\n    return df_in\n\n\nsample_df = compile_results(sample_df, init_shape_res)\n\n# define X and y to train the initial model\nX_initial = sample_df.fp.values\ny_initial = sample_df.score.values\n\n# instantiate the optimizer with an estimator, training data, and an acquistion function\n\noptimizer = BayesianOptimizer(estimator=GaussianProcessRegressor(kernel=TanimotoKernel()),\n                              X_training=np.stack(X_initial), y_training=y_initial,\n                              query_strategy=query_strategy)\n\n# initalize a list of results\nresult_list = [sample_df]\nused = list(sample_df.index)\n\n# the active learning loop\nfor i in range(0, n_cycles):\n    # ask the optimizer for the next set of molecules\n    query_idx, query_desc = optimizer.query(X_pool, n_instances=n_instances, used=used)\n    # create dataframe with the next set of molecules\n    tmp_df = df.iloc[query_idx].copy()\n    # get the shape scores\n    shape_res = oracle.get_values(tmp_df.SMILES.values)\n    # add the results to the dataframe\n    tmp_df = compile_results(tmp_df, shape_res)\n    tmp_df['cycle'] = i+1\n    # add the current dataframe to result_list\n    result_list.append(tmp_df)\n    # keep track of the molecules we've used\n    used += list(tmp_df.index)\n    # update the optimizer with the new values\n    #optimizer.teach(query_desc, tmp_df.score.values)\n    optimizer.teach(np.stack(tmp_df.fp.values), tmp_df.score.values)\n\n\n将主动学习周期的结果合并到一个数据框中。\n\n\ncombo_df = pd.concat(result_list)\nlen(combo_df)\n\n\n查看主动学习选择的分数分布。\n\n\n# sns.displot(x=\"score\",data=combo_df);\n\n\n\n\n\nggplot(py$combo_df, aes(x = score)) +\n  geom_histogram(binwidth = 0.5) +\n  labs(title = \"Distribution of Scores for Random Selection\",\n       x = \"Score\") +\n  myggtheme\n\n\n\n\n运行随机选择以与主动学习进行比较\n主动学习真的更好吗？让我们选择 600 个随机分子，并与使用主动学习选择的 600 个分子进行比较。\n\n\nrandom_df = df.sample(600).copy()\nrandom_shape_res = oracle.get_values(random_df.SMILES.values)\nrandom_df = compile_results(random_df, random_shape_res)\n\n\n查看随机选择的分数分布\n\n\n# sns.displot(x=\"score\",data=random_df);\n\n\n\n\n\nggplot(py$random_df, aes(x = score)) +\n  geom_histogram(binwidth = 0.5) +\n  labs(title = \"Distribution of Scores for Random Selection\",\n       x = \"Score\") +\n  myggtheme\n\n\n\n\n将随机选择的分数与主动学习进行比较。\n\n\nactive_top_100_df = combo_df.sort_values(\"score\",ascending=False).head(100)\nactive_top_100_df['dataset'] = \"active learning\"\nrandom_top_100_df = random_df.sort_values(\"score\",ascending=False).head(100)\nrandom_top_100_df['dataset'] = \"random\"\nplot_df = pd.concat([active_top_100_df, random_top_100_df])\nsns.boxplot(x=\"dataset\",y=\"score\",data=plot_df);\n\n\n\n\n\nggplot(py$plot_df,aes(x = dataset, y = score)) +\n  geom_boxplot() +\n  labs(title = \"Distribution of Scores for Random Selection vs. Active Learning\",\n       x = \"Dataset\",\n       y = \"Score\") +\n  myggtheme\n\n\n\n\n绘制每个主动学习轮中选择的分子的分数。请记住，第一个主动学习周期是随机选择的。\n\n\nax = sns.boxplot(x=\"cycle\", y=\"score\", data=combo_df,color=\"lightblue\")\nax.set_xlabel(\"Active Learning Cycle\");\n\n\n\n\n\npy$combo_df %>%\n  mutate(cycle = as.factor(cycle)) %>%\n  ggplot(., aes(x = cycle, y = score, fill = cycle)) +\n  geom_boxplot() +\n  labs(title = \"Scores of Molecules Selected in Each Active Learning Round\",\n       x = \"Active Learning Cycle\",\n       y = \"Score\") +\n  myggtheme\n\n\n\n\n检查最高分叠加项，确保我们的结果合理, 我们将使用 Py3DMol 来完成此操作。\n\n\nquery_mol = Chem.MolFromMolFile(\"data/2chw_lig.sdf\")\n# get the highest scoring molecule from combo_df\ndb_mol = combo_df.sort_values(\"score\",ascending=False).shape_res.values[0].best_mol\ndb_mol = Chem.RemoveHs(db_mol)\n# For Py3DMol, we need to convert molecules to molblocks\nquery_mblock = Chem.MolToMolBlock(query_mol)\ndb_mblock = Chem.MolToMolBlock(db_mol)\n# create a Py3DMol view\nview = py3Dmol.view()\n# add the molecules\nview.addModel(query_mblock, 'mol')\nview.addModel(db_mblock, 'mol')\n# color the molecules\nview.setStyle({'model': 0},{'stick':{'colorscheme':'greenCarbon'}})\nview.setStyle({'model': 1},{'stick':{'colorscheme':'lightgreyCarbon'}})\n# Zoom in and show the molecules\nview.zoomTo()\nview.show()\n\n\n\n\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2024-04-09T21:20:51+08:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-05-15-figreproduction001/",
    "title": "Fig_reproduction_001",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Jixing Liu",
        "url": "https://jixing475.github.io/jixingBlog"
      }
    ],
    "date": "2022-05-15",
    "categories": [
      "experimental design",
      "R"
    ],
    "contents": "\n\nContents\nSelected article:\nthe original figure:\nImport libraries\nPrepare fabricated data\nConvert\npossible original dataset to TIDY data\nR codes for the figure\nFinal replica\nSome personal\nrecommendations:\n\nFirst week’s figure is from an RCT published in JAMA Surgery. Codes\nfor the replica of Figure-1B will be here.\nSelected article:\nTitle: Impact\nof Portable Normothermic Blood-Based Machine Perfusion on Outcomes of\nLiver Transplant The OCS Liver PROTECT Randomized Clinical\nTrial\nJournal: JAMA Surgery\nAuthors: Markmann JF, Abouljoud MS, Ghobrial RM, et\nal.\nYear: 2022\nPMID: 34985503\nDOI: 10.1001/jamasurg.2021.6781\n\nthe original figure:\nFigure-1BImport libraries\n\n\n\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(fabricatr)      # to fabricate fake data\nlibrary(ggsci)          # for using JAMA color pallette (not needed here)\n\ntheme_set(theme_light(base_family = \"Open Sans\")) # Updated on 2022-01-24 (\"Helvetica Neue\" was converted to \"Open Sans\")\n\n\n\n\n\nPrepare fabricated data\n\n\n\n\n# prepare a dataset for group 1:\nset.seed(2022)\nOCS_liver <- fabricate(\n  N = 152,\n  group = \"OCS_liver\",\n  time_0 = round(rnorm(N, mean = 7.4, sd = 2.9),2),\n  time_0.5 = round(rnorm(N, mean = 3.8, sd = 2.2),2),\n  time_1.0 = round(rnorm(N, mean = 2.6, sd = 2.8),2),\n  time_1.5 = round(rnorm(N, mean = 1.4, sd = 1.45),2),\n  time_2.0 = round(rnorm(N, mean = 1.5, sd = 1.2),2),\n  time_2.5 = round(rnorm(N, mean = 1.3, sd = 1.3),2),\n  time_3.0 = round(rnorm(N, mean = 1.2, sd = 1.0),2),\n  time_3.5 = round(rnorm(N, mean = 1.3, sd = 0.9),2),\n  time_4.0 = round(rnorm(N, mean = 1.5, sd = 0.7),2),\n  time_4.5 = round(rnorm(N, mean = 1.4, sd = 1.0),2),\n  time_5.0 = round(rnorm(N, mean = 1.5, sd = 0.8),2),\n  time_5.5 = round(rnorm(N, mean = 1.4, sd = 1.0),2)) %>% \n  as_tibble() \n\n\n# prepare a dataset for group 2:\nset.seed(2022) \nICS <- fabricate( # because the n is too small, I preferred manual values for some.\n  N = 3,\n  group = \"ICS\",\n  time_0 = c(9.2, 9.8, 10.4),\n  time_0.5 = c(8.8, 9.4, 10.4),\n  time_1.0 = round(rnorm(N, mean = 10.5, sd = 0),2),\n  time_1.5 = c(10, 11.1, 12.2),\n  time_2.0 = round(rnorm(N, mean = 11, sd = 0),2)) %>% \n  as_tibble()\n\n\n\n# Combine two dataset\ncombined_dataset <-  bind_rows(OCS_liver, ICS) %>% \n  mutate (patient_id = paste0(\"P_\", row_number())) %>% \n  select(patient_id, everything(), -ID)\n\n\n\n\n\nConvert possible\noriginal dataset to TIDY data\n\n\n\ntidy_data <- combined_dataset %>% \n  pivot_longer(starts_with(\"time\"),\n               names_to = \"time\",\n               values_to = \"values\") %>%\n  filter(!is.na(values)) %>% \n  # mutate(values = if_else(values<=0, 0, values)) %>% # this is a possible mistake in the article figure. SD should not go below 0.\n  group_by(group, time) %>% \n  summarise(mean= mean(values, na.rm = TRUE),\n            sd= sd(values, na.rm = TRUE))  %>% \n  ungroup() %>% \n  separate(time, into = c(\"blank\", \"time\"), sep = \"_\") %>% \n  mutate(time = factor(time)) \n\ntidy_data %>% head()\n\n\n# A tibble: 6 × 5\n  group     blank time   mean    sd\n  <chr>     <chr> <fct> <dbl> <dbl>\n1 ICS       time  0      9.8  0.600\n2 ICS       time  0.5    9.53 0.808\n3 ICS       time  1.0   10.5  0    \n4 ICS       time  1.5   11.1  1.1  \n5 ICS       time  2.0   11    0    \n6 OCS_liver time  0      7.60 2.98 \n\n\n\nR codes for the figure\n\n\n\nw1_replica <- tidy_data %>% \n  ggplot(aes(time, mean, color = group)) +\n  geom_errorbar(data = . %>% filter(sd != 0), # single errorbar was ok, but colors of edges and lines are different. Therefore, I used an additional geom_linerange\n                aes(ymin = mean - sd, ymax = mean + sd), width = .3, size = .3, show.legend = F) + \n  geom_linerange(aes(ymin = mean - sd, ymax = mean + sd), color = \"black\", size = .3) +\n  geom_point(size = 3) +\n  geom_line(aes(group = group), size = .6, show.legend = F) +\n  # scale_color_jama(labels =c(\"ICS\" = \"Turned down\",\"OCS_liver\" = \"Transplanted\")) + # JAMA has its own color palette, but I preferred using manual values.\n  scale_color_manual(values = c( \"ICS\" = \"#244551\",\"OCS_liver\" = \"#F28118\"), labels =c(\"ICS\" = \"Turned down\",\"OCS_liver\" = \"Transplanted\")) +\n  scale_y_continuous(breaks = seq(0,14,2), labels = number_format(accuracy = 1)) +\n  labs(x = \"Time on OCS Liver, h\",\n       y = \"Mean arterial lactate, mmol/L\",\n       title = \"Lactate levels during OCS Liver perfusion\\n\") +\n  theme(panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.major.y = element_line(color = \"lightgray\", size = .3),\n        panel.grid.minor.y = element_blank(),\n        panel.border = element_blank(),\n        axis.line = element_line(colour = \"black\"),\n        axis.ticks.length = unit(.20, \"cm\"),\n        axis.ticks = element_line(color = \"black\", size = .5),\n        axis.text = element_text(color = \"black\", size = 10),\n        axis.title.x = element_text(size = 10, vjust = -1),\n        axis.title.y = element_text(size = 10, vjust = 1),\n        legend.title = element_blank(),\n        legend.background = element_rect(colour = \"black\", size = .2),\n        legend.position = c(.80, .75),\n        legend.text = element_text(size = 9),\n        legend.text.align = .5,\n        legend.spacing.y = unit(0, \"cm\"),\n        legend.spacing.x = unit(0, \"cm\"),\n        legend.key.height = unit(.4, \"cm\"),\n        plot.margin = unit(c(1,1,1,1), \"cm\"),\n        plot.title = element_text(hjust = -0.1, vjust = 2)) +\n  guides(colour = guide_legend(override.aes = list(shape = 16, size = 3))) +\n  coord_cartesian(xlim = c(0.5, n_distinct(tidy_data$time)), ylim = c(-0.5, 14), expand = 0, clip = \"off\")  # using n_distinct is better than 12 for reproducibility.\n\n# ggsave(w1_replica,\n#        # filename = \"content/blog/2022-01-18-week-1/w1_replica.jpg\",\n#        filename = \"w1_replica.jpg\",\n#        dpi = 300,\n#        width = 5,\n#        height = 4)\n\n\n\n\n\n\nFinal replica\n\n\n\n\nw1_replica\n\n\n\n\n\nSome personal\nrecommendations:\nMajor:\n1. I would not prefer using negative SD (lower threshold of 1sd of mean)\nvalues.\n1. There is an overlap in the errorbars on time-0. I would prefer using\nposition_dodge.\n1. visualizing a distribution for a small-sized group (n = 3) may not be\na good idea.\nMinor:\n1. I would not prefer using 1.0, 2.0, 3.0, etc. 1, 2, 3, is ok.\nNotes: 1. The management of tags is ok with patchwork\npackage, and should be done at the end.\n1. I m not sure about the font. an update may be required. (updated to\n“Open Sans”) 1. figure ratio in the blog is slightly different than the\nrstudio version. \n\n\n\n",
    "preview": "posts/2022-05-15-figreproduction001/figures/unnamed-chunk-5-1.png",
    "last_modified": "2024-04-07T11:55:28+08:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-02-03-current-state-of-experimental-design-r-packages/",
    "title": "Current state of R packages for the design of experiments",
    "description": "Your analytical toolkit matters very little if the data are no good. Ideally you want to know to how the data were collected before delving into the analysis of the data; better yet, get involved _before_ the collection of data and design its collection. In this post I explore some of the top downloaded R packages for the design of experiments and analysis of experimental data.",
    "author": [
      {
        "name": "Jixing Liu",
        "url": "https://jixing475.github.io/jixingBlog"
      }
    ],
    "date": "2021-02-03",
    "categories": [
      "experimental design",
      "R"
    ],
    "contents": "\n\nContents\nData collection\nExperimental data\n\nDesign and analysis of experiments\nBigram of DoE package titles and descriptions\nNetwork of DoE package imports and dependencies\nCRAN download logs\nTop 5 DoE packages\n\nR-packages\nAlgDesign\nagricolae\nlhs\nez\nDoE.base\n\n\n\n\n\n\n\n\nClick Me\n\nto see all code in this article. You can also find the link to the source Rmd file at the footer.\n\n\n\n\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(lubridate)\nlibrary(cranlogs)\nlibrary(glue)\nlibrary(scales)\nlibrary(colorspace)\nlibrary(tidytext)\nlibrary(pluralize)\nlibrary(kableExtra)\nlibrary(igraph)\nlibrary(ggraph)\n\nmyggtheme <- \n  theme(panel.background = element_rect(fill = NA),\n        panel.grid = element_line(color = \"#f6e5ee\"),\n        axis.text = element_text(color = \"#4B8160\"),\n        axis.line = element_line(color = \"#4B8160\", size = 0.7),\n        axis.ticks.length = unit(1.4, \"mm\"),\n        axis.ticks = element_line(color = \"#4B8160\", size = 0.7),\n        axis.title = element_text(color = \"#4B8160\", face = \"bold\"),\n        strip.background = element_rect(color = \"#4B8160\",\n                                        fill = \"#4B8160\"),\n        strip.text = element_text(color = \"white\"),\n        plot.title.position = \"plot\",\n        plot.title = element_text(color = \"#4B8160\", face = \"bold\")) \n\n\n\n\n\n\n\n# Thanks to Dirk Eddelbuettel's answer on SO:\n# https://stackoverflow.com/questions/11560865/list-and-description-of-all-packages-in-cran-from-within-r\nurl <- paste0(getOption(\"repos\")[\"CRAN\"], \"web/packages/packages.rds\")\ndb <- readRDS(url(url)) %>% \n  as.data.frame()\n\n\n\n\n\n\n\nnanalysis <- db %>% \n  filter(str_detect(tolower(Title), \"analysis\")) %>% \n  nrow()\n\nndesign <- db %>% \n  filter(str_detect(tolower(Title), \"design\")) %>% \n  nrow()\n\n\n\n\nData collection\nAs many know, it doesn’t matter how good your analytical tools is if your data are rubbish. This sentiment is often captured in the expression “garbage in, garbage out”. It’s something we all seem to know but there is still a tendency for many of us to place a greater focus on the analysis1. This is perhaps all natural given that a potential for discovery is just so much more exciting than ensuring the quality of the collected data.\nSo what is considered as good quality data? A lack of error in the data? Data containing enough range of variables and sample size for the downstream analysis? Giving an explicit definition of a good quality data is a fraught exercise, but if you know how the data were collected then you can better perform the initial data analysis (Chatfield 1985) to weed out (or fix) potential poor quality data. This step will likely get more value out of the data than fitting complex models to poor quality data.\nBetter than knowing how the data were collected, if you can design the collection of data so that it’s optimised for the purpose of the analysis2, then you can potentially get even a better value out of your data. Not all data collection starts with an explicit analytical plan though. Furthermore, you may have very little control of how the data are collected. Often these are observational data or making a secondary use of experimental data. This article will focus on data collection of an experiment where you have some control of the collection process.\nExperimental data\nAll experiments are conducted with some objective in mind. This could be that a scientist may wish to test their hypothesis, a manufacturer wants to know which manufacturing process is better or a researcher wants to understand some cause-and-effect relationships. A characteristic part of an experiment is that the experimenter has control over some explanatory variables. In a comparative experiment, the control is over the allocation of treatments to subjects. Designing an experiment in the statistics discipline usually focus on this allocation, although it’s important to keep in mind that there are other decision factors in an experiment.\nData that are collected from experiments are what we refer to as experimental data. Because it was collected with some objective in mind followed by some data collection plan, experimental data are often thought of to be better quality than observational data. But then again if you can’t quantify the quality of data, you can’t really tell. Certain scientific claims (e.g. causation, better treatment) can only be substantiated by experiments and so experimental data is held to a higher standard in general.\nDesign and analysis of experiments\n\n\n\ndat_DoE <- read_html(\"https://cran.r-project.org/web/views/ExperimentalDesign.html\")\ndate_download <- Sys.Date()\ncran_names <- available.packages() %>% \n  rownames() %>% \n  unique() # it should be unique\ndoe_pkgs <- dat_DoE %>% \n  html_nodes(\"li\") %>% \n  html_nodes(\"a\") %>% \n  html_text() %>% \n  .[. %in% cran_names] %>% \n  unique()\n\ndat_survey <- read_html(\"https://cran.r-project.org/web/views/OfficialStatistics.html\")\nsurvey_pkgs <- dat_survey %>% \n  html_nodes(\"li\") %>% \n  html_nodes(\"a\") %>% \n  html_text() %>% \n  .[. %in% cran_names] %>% \n  unique()\n\n\n\n\nThere are all together 113 R-packages in the CRAN Task View of Design of Experiments & Analysis of Experimental Data as of 2021-02-07.3 I’m going to refer these packages as DoE packages, although there are some packages in the mix that are more about the analysis of experimental data rather than the design of experiments and there are some packages that are missing in the list (e.g. DeclareDesign). The DoE packages make up about 0.7% of the 17,036 packages available in CRAN.\nThe DoE packages don’t include survey design. These instead belong to the CRAN Task View of Official Statistics & Survey Methodology which contains 132 packages. While some surveys are part of an experimental study, most often they generate observational data.\nBelow I have a number of different analysis for these DoE packages. If you push the button on the top right corner of this article, you can toggle the display for the code or alternatively you can have a look at the source Rmd document.\nBigram of DoE package titles and descriptions\n\n\n\nstop_words_ext <- c(stop_words$word, \"doi\")\n\ndoe_db <- db %>% \n  filter(Package %in% doe_pkgs) %>% \n  mutate(Description = str_replace_all(Description, \"\\n\", \" \"),\n         Description = str_squish(Description),\n         Title = str_replace_all(Title, \"\\n\", \" \"))\n\nbigram_tab <- function(data, col) {\n  data %>% \n    unnest_tokens(word, {{col}}, token = \"ngrams\", n = 2) %>% \n    separate(word, c(\"word1\", \"word2\"), sep = \" \") %>% \n    mutate(word1 = singularize(word1),\n           word2 = singularize(word2)) %>% \n    # don't count the same bigram within the same package\n    distinct(Package, word1, word2) %>% \n    filter(!word1 %in% stop_words_ext,\n           !word2 %in% stop_words_ext,\n           !str_detect(word1, \"^[0-9.]+$\"),\n           !str_detect(word2, \"^[0-9.]+$\")) %>% \n    count(word1, word2, sort = TRUE)  \n}\n\n\n\n\n\n\n\nbigram_tab(doe_db, Description) %>% \n  filter(n > 4) %>% \n  mutate(word = paste(word1, word2)) %>% \n  select(word, n) %>% \n  kbl(caption = \"The bigram of the R-package _descriptions_ as provided in the DESCRIPTION file in CRAN.\", \n               col.names = c(\"Bigram\", \"Count\")) %>% \n  kable_classic(full_width = FALSE)\n\n\n\n\n\n\n\nbigram_tab(doe_db, Title) %>% \n  filter(n > 3) %>% \n  mutate(word = paste(word1, word2)) %>% \n  select(word, n) %>% \n  kbl(caption = \"The bigram of the R-package _titles_ as provided in the DESCRIPTION file in CRAN.\", \n               col.names = c(\"Bigram\", \"Count\")) %>% \n  kable_classic(full_width = FALSE)\n\n\n\n\nTable 1 shows the most common bigrams in the title of the DoE packages. It’s perhaps not surprising but the words “optimal design” and “experimental design” are the top. It’s also likely that the words “design of experiments” appears often but because this is a bigram (two consecutive words) so it doesn’t appear. You might then wonder if that’s the case words like “design of” or “of experiments” should make an appearance, however “of” is a stop word and these are filtered out otherwise unwanted bigrams come up on the top.\nThere are couple of words like “clinical trial” and “dose finding” that suggests applications in medical experiments, as well as “microarray experiment” that suggests application in bioinformatics.\n\n\nTable 1: The bigram of the R-package titles as provided in the DESCRIPTION file in CRAN.\n\n\nBigram\n\n\nCount\n\n\noptimal design\n\n\n10\n\n\nexperimental design\n\n\n8\n\n\nclinical trial\n\n\n5\n\n\ndose finding\n\n\n5\n\n\nsequential design\n\n\n5\n\n\nblock design\n\n\n4\n\n\nmicroarray experiment\n\n\n4\n\n\nresponse surface\n\n\n4\n\n\nThe title alone might be too succinct for text analysis so I also had a look at the most common bigrams in the description of the DoE packages as shown in Table 2. The counts in Table 2 (and also Table 1) is across the DoE packages. To be more clear, even if the bigram is mentioned multiple times within the description, it’s only counted once per package. This removes the inflation of the counts due to one package mentioning the same bigram over and over again.\nAgain not surprisingly “experimental design” and “optimal design” comes on top in the DoE package descriptions. The words “graphical user” and “user interface” implies that the trigram “graphical user interface” was probably common.\n\n\nTable 2: The bigram of the R-package descriptions as provided in the DESCRIPTION file in CRAN.\n\n\nBigram\n\n\nCount\n\n\nexperimental design\n\n\n11\n\n\noptimal design\n\n\n10\n\n\npackage provide\n\n\n7\n\n\nresponse surface\n\n\n7\n\n\nfactorial design\n\n\n6\n\n\ngraphical user\n\n\n6\n\n\nuser interface\n\n\n6\n\n\nblock design\n\n\n5\n\n\ncontour plot\n\n\n5\n\n\ndesign based\n\n\n5\n\n\neffect model\n\n\n5\n\n\nfractional factorial\n\n\n5\n\n\nmicroarray experiment\n\n\n5\n\n\nmixed effect\n\n\n5\n\n\nprovide function\n\n\n5\n\n\nsample size\n\n\n5\n\n\nsequential design\n\n\n5\n\n\nNetwork of DoE package imports and dependencies\n\n\n\ndoe_imports <- doe_db %>% \n  mutate(Depends = str_replace_all(Depends, \"\\n\", \" \"),\n         Depends = str_replace_all(Depends, fixed(\"(\"), \" (\"),\n         Imports = str_replace_all(Imports, \"\\n\", \" \"),\n         Imports = str_replace_all(Imports, fixed(\"(\"), \" (\"),\n         imports = str_c(Depends, Imports, sep = \",\"),\n         imports = str_split(imports, \",\"),\n         imports = map(imports, ~{\n                    str_squish(.x) %>% \n                      word() %>% \n                      .[.!=\"\"]}\n           ),\n         imports_doe = map(imports, ~.x[.x %in% doe_pkgs])) %>% \n  select(Package, imports_doe) %>% \n  unnest_longer(imports_doe) %>% \n  filter(!is.na(imports_doe)) %>% \n  rename(from = imports_doe, to = Package) %>% \n  select(from, to)\n\n\n\n\nFigure 1 shows the imports and dependency between the DoE packages. We can see here that DoE.wrapper imports a fair number of DoE packages that results in the major network cluster see in Figure 1. AlgDesign and DoE.base are imported into four other DoE packages so form an important base in the DoE world.\n\n\n\ngraph_from_data_frame(doe_imports) %>% \n  ggraph(layout = 'fr') +\n  geom_edge_link(aes(start_cap = label_rect(node1.name),\n                     end_cap = label_rect(node2.name)), \n                 arrow = arrow(length = unit(2, 'mm')),\n                 color = \"#4B8160\") + \n  geom_node_text(aes(label = name),\n                 color = \"#4B8160\") +\n  theme(panel.background = element_rect(fill = \"#f6e5ee\",\n                                        color = \"#4B8160\"),\n        plot.margin = margin(20, 20, 20, 20))\n\n\n\n\n\n\n\n\nFigure 1: The network of imports and dependency among DoE packages alone. Each node represents a DoE package. DoE packages with no imports or dependency on other DoE packages are excluded. Each arrow represents the relationship between the packages such that the package on the tail is used by package on the head of the arrow.\n\n\n\nCRAN download logs\n\n\n\nend <- Sys.Date() - 2 # usually 1-2 days are not available yet\nstart <- end - years(5) + days(2)\ndldat <- cran_downloads(doe_pkgs, from = start, to = end)\n\n\n\n\n\n\n\ndldat %>% \n    group_by(package) %>% \n    summarise(total = sum(count)) %>%\n  ggplot(aes(total)) + \n  geom_histogram(color = \"white\", fill = \"#4B8160\") + \n  scale_x_log10(label = comma) + \n  myggtheme + \n  labs(x = glue(\"Total download counts from {start} to {end}\"),\n       y = \"Number of packages\") +\n  scale_y_continuous(expand = c(0, 0))\n\n\n\n\nFigure 2 shows the distribution of the total download counts over the last 5 years4 of the DoE packages. This graph doesn’t take into account that some DoE packages may only have been on CRAN in the last 5 years so the counts are in favour of DoE packages that’s been on CRAN longer.\n\n\n\n\nFigure 2: Histogram of the total download count over last 5 years of the DoE packages.\n\n\n\nTop 5 DoE packages\n\n\n\nntop <- 5\n\ntop5sum_df <- dldat %>% \n  group_by(package) %>% \n  summarise(total = sum(count)) %>% \n  ungroup() %>% \n  slice_max(order_by = total, n = ntop)\n\ntop5 <- top5sum_df %>% \n  pull(package) \n\ntop5_df <- dldat %>% \n  filter(package %in% top5) %>% \n  mutate(package = fct_reorder(package, count, function(x) -sum(x))) \n\n\n\n\nThe top 5 downloaded DoE packages at the time of this writing are AlgDesign, agricolae, lhs, ez, and DoE.base. You can see the download counts in Figure 3.\n\n\n\ntop5sum_df %>% \n  mutate(package = fct_reorder(package, total)) %>% \n  ggplot(aes(total, package)) +\n  geom_col(aes(fill = package)) +\n  labs(x = glue(\"Total downloads from {start} to {end}\"),\n       y = \"Package\") + \n  scale_x_continuous(labels = comma, expand = c(0, 0)) +\n  myggtheme + \n  scale_fill_discrete_qualitative(rev = TRUE) + \n  guides(fill = FALSE)\n\n\n\n\n\n\n\n\nFigure 3: The above barplot shows the total downloads of the top 5 downloaded DoE packages from the period 2016-02-07 to 2021-02-05.\n\n\n\nWe can have a look at further examination of the top 5 DoE packages by looking at the daily download counts as shown in Figure 3. The download counts are the raw values and these include downloads by CRAN mirror and bots. There is a noticeable spike when there is an update to the CRAN package. This is partly because when there is a new version of the package, when you install other packages that depend or import it then R will prompt you to install the new version. This means that the download counts are inflated and to some extent you can artificially boost them by making regular CRAN updates. The adjustedcranlogs (Morgan-Wall 2017) makes a nice attempt to adjust the raw counts based on a certain heuristic. I didn’t use it since the adjustment is stochastic and I appear to have hit a bug.\n\n\n\npkg_url <- \"https://cran.r-project.org/web/packages/{pkg}/index.html\"\npkg_archive <- \"https://cran.r-project.org/src/contrib/Archive/{pkg}/\"\npkg_updates <- map(top5, function(pkg) {\n    last_update <- read_html(glue(pkg_url)) %>% \n      html_table() %>% \n      .[[1]] %>% \n      filter(X1==\"Published:\") %>% \n      pull(X2) %>% \n      ymd()\n      \n    archive_dates <- tryCatch({ \n        read_html(glue(pkg_archive)) %>% \n          html_table() %>%\n          .[[1]] %>% \n          pull(`Last modified`) %>% \n          ymd_hm() %>% \n          na.omit() %>% \n          as.Date()\n      }, error = function(e) {\n        NULL\n      })\n    c(archive_dates, last_update)\n  })\nnames(pkg_updates) <- top5\n\nupdates <- unlist(pkg_updates) %>% \n  enframe(\"package\", \"update\") %>% \n  # unlist converts date to integers\n  mutate(update = as.Date(update, origin = \"1970-01-01\"),\n         # need to get rid of the numbers appended to pkg names\n         package = str_extract(package, paste0(top5, collapse=\"|\")),\n         package = factor(package, levels = top5)) %>% \n  filter(between(update, start, end))\n\n\n\n\n\n\n\nggplot(top5_df, aes(date, count, color = package)) +\n  # add shadow lines\n  geom_line(data = rename(top5_df, package2 = package), \n            color = \"gray\", aes(group = package2)) +\n  # add date when package was updated\n  geom_vline(data = updates, aes(xintercept = update),\n             linetype = \"dashed\", color = \"#4B8160\") + \n  # the trend line\n  geom_line() +\n  scale_y_log10() +\n  facet_grid(package ~ .) + \n  labs(title = glue(\"Top 5 downloaded DoE packages from {start} to {end}\")) + \n  scale_color_discrete_qualitative() +\n  guides(color = FALSE) +\n  myggtheme\n\n\n\n\n\n\n\n\nFigure 4: The above plot shows the daily downloads of the top 5 downloaded DoE packages from the period 2016-02-07 to 2021-02-05. The vertical dotted bar corresponds to the date that a new version of the corresponding package was released on CRAN.\n\n\n\nR-packages\nHere we have a closer look at the functions of the top 5 downloaded DoE packages below ordered by their download counts.\nAlgDesign  CRAN  GitHub  Wheeler (2019)Algorithmic Experimental Design\nOriginally written by  Bob Wheeler but  Jerome Braun have taken over maintenance of the package.\nagricolae  CRAN  de Mendiburu (2020)Statistical Procedures for Agricultural Research\nWritten and maintained by  Felipe de Mendiburu\nlhs  CRAN  GitHub  Carnell (2020)Latin Hypercube Samples\nWritten and maintained by  Rob Carnell\nez  CRAN  GitHub  Lawrence (2016)Easy Analysis and Visualization of Factorial Experiments\nWritten and maintained by  Michael A. Lawrence\nDoE.base  CRAN  Grömping (2018)Full Factorials, Orthogonal Arrays and Base Utilities for DoE Packages\nWritten and maintained by  Ulrike Groemping.\n\nInterestingly these top 5 DoE packages have only one active author. Bob Wheeler doesn’t seem to actively contribute to AlgDesign any longer; and there are two contributors for DoE.base but are not listed as authors.\nBefore we look at the packages, let’s set a seed so we can reproduce the results.\n\n\nset.seed(2021)\n\n\n\nAlgDesign\nTo start off, we begin with the most downloaded DoE package, AlgDesign. The examples below are taken directly from the vignette of the AlgDesign package.\n\n\nlibrary(AlgDesign)\n\n\n\nYou can create a balanced incomplete block design using the optBlock function. It’s using an optimal design framework where the default criterion is D criterion and the implied model is given in the first argument.\n\n\nBIB <- optBlock(~ ., \n                withinData = factor(1:7), \n                blocksize = rep(3, 7))\nBIB\n\n\n$D\n[1] 0.08033556\n\n$diagonality\n[1] 0.692\n\n$Blocks\n$Blocks$B1\n  X1\n1  1\n3  3\n4  4\n\n$Blocks$B2\n  X1\n2  2\n4  4\n5  5\n\n$Blocks$B3\n  X1\n4  4\n6  6\n7  7\n\n$Blocks$B4\n  X1\n3  3\n5  5\n6  6\n\n$Blocks$B5\n  X1\n2  2\n3  3\n7  7\n\n$Blocks$B6\n  X1\n1  1\n2  2\n6  6\n\n$Blocks$B7\n  X1\n1  1\n5  5\n7  7\n\n\n$design\n   X1\n1   1\n3   3\n4   4\n2   2\n41  4\n5   5\n42  4\n6   6\n7   7\n31  3\n51  5\n61  6\n21  2\n32  3\n71  7\n11  1\n22  2\n62  6\n12  1\n52  5\n72  7\n\n$rows\n [1] 1 3 4 2 4 5 4 6 7 3 5 6 2 3 7 1 2 6 1 5 7\n\nAlgDesign also includes helper functions to generate a factorial structure.\n\n\ndat <- gen.factorial(2, 7)\ndat\n\n\n    X1 X2 X3 X4 X5 X6 X7\n1   -1 -1 -1 -1 -1 -1 -1\n2    1 -1 -1 -1 -1 -1 -1\n3   -1  1 -1 -1 -1 -1 -1\n4    1  1 -1 -1 -1 -1 -1\n5   -1 -1  1 -1 -1 -1 -1\n6    1 -1  1 -1 -1 -1 -1\n7   -1  1  1 -1 -1 -1 -1\n8    1  1  1 -1 -1 -1 -1\n9   -1 -1 -1  1 -1 -1 -1\n10   1 -1 -1  1 -1 -1 -1\n11  -1  1 -1  1 -1 -1 -1\n12   1  1 -1  1 -1 -1 -1\n13  -1 -1  1  1 -1 -1 -1\n14   1 -1  1  1 -1 -1 -1\n15  -1  1  1  1 -1 -1 -1\n16   1  1  1  1 -1 -1 -1\n17  -1 -1 -1 -1  1 -1 -1\n18   1 -1 -1 -1  1 -1 -1\n19  -1  1 -1 -1  1 -1 -1\n20   1  1 -1 -1  1 -1 -1\n21  -1 -1  1 -1  1 -1 -1\n22   1 -1  1 -1  1 -1 -1\n23  -1  1  1 -1  1 -1 -1\n24   1  1  1 -1  1 -1 -1\n25  -1 -1 -1  1  1 -1 -1\n26   1 -1 -1  1  1 -1 -1\n27  -1  1 -1  1  1 -1 -1\n28   1  1 -1  1  1 -1 -1\n29  -1 -1  1  1  1 -1 -1\n30   1 -1  1  1  1 -1 -1\n31  -1  1  1  1  1 -1 -1\n32   1  1  1  1  1 -1 -1\n33  -1 -1 -1 -1 -1  1 -1\n34   1 -1 -1 -1 -1  1 -1\n35  -1  1 -1 -1 -1  1 -1\n36   1  1 -1 -1 -1  1 -1\n37  -1 -1  1 -1 -1  1 -1\n38   1 -1  1 -1 -1  1 -1\n39  -1  1  1 -1 -1  1 -1\n40   1  1  1 -1 -1  1 -1\n41  -1 -1 -1  1 -1  1 -1\n42   1 -1 -1  1 -1  1 -1\n43  -1  1 -1  1 -1  1 -1\n44   1  1 -1  1 -1  1 -1\n45  -1 -1  1  1 -1  1 -1\n46   1 -1  1  1 -1  1 -1\n47  -1  1  1  1 -1  1 -1\n48   1  1  1  1 -1  1 -1\n49  -1 -1 -1 -1  1  1 -1\n50   1 -1 -1 -1  1  1 -1\n51  -1  1 -1 -1  1  1 -1\n52   1  1 -1 -1  1  1 -1\n53  -1 -1  1 -1  1  1 -1\n54   1 -1  1 -1  1  1 -1\n55  -1  1  1 -1  1  1 -1\n56   1  1  1 -1  1  1 -1\n57  -1 -1 -1  1  1  1 -1\n58   1 -1 -1  1  1  1 -1\n59  -1  1 -1  1  1  1 -1\n60   1  1 -1  1  1  1 -1\n61  -1 -1  1  1  1  1 -1\n62   1 -1  1  1  1  1 -1\n63  -1  1  1  1  1  1 -1\n64   1  1  1  1  1  1 -1\n65  -1 -1 -1 -1 -1 -1  1\n66   1 -1 -1 -1 -1 -1  1\n67  -1  1 -1 -1 -1 -1  1\n68   1  1 -1 -1 -1 -1  1\n69  -1 -1  1 -1 -1 -1  1\n70   1 -1  1 -1 -1 -1  1\n71  -1  1  1 -1 -1 -1  1\n72   1  1  1 -1 -1 -1  1\n73  -1 -1 -1  1 -1 -1  1\n74   1 -1 -1  1 -1 -1  1\n75  -1  1 -1  1 -1 -1  1\n76   1  1 -1  1 -1 -1  1\n77  -1 -1  1  1 -1 -1  1\n78   1 -1  1  1 -1 -1  1\n79  -1  1  1  1 -1 -1  1\n80   1  1  1  1 -1 -1  1\n81  -1 -1 -1 -1  1 -1  1\n82   1 -1 -1 -1  1 -1  1\n83  -1  1 -1 -1  1 -1  1\n84   1  1 -1 -1  1 -1  1\n85  -1 -1  1 -1  1 -1  1\n86   1 -1  1 -1  1 -1  1\n87  -1  1  1 -1  1 -1  1\n88   1  1  1 -1  1 -1  1\n89  -1 -1 -1  1  1 -1  1\n90   1 -1 -1  1  1 -1  1\n91  -1  1 -1  1  1 -1  1\n92   1  1 -1  1  1 -1  1\n93  -1 -1  1  1  1 -1  1\n94   1 -1  1  1  1 -1  1\n95  -1  1  1  1  1 -1  1\n96   1  1  1  1  1 -1  1\n97  -1 -1 -1 -1 -1  1  1\n98   1 -1 -1 -1 -1  1  1\n99  -1  1 -1 -1 -1  1  1\n100  1  1 -1 -1 -1  1  1\n101 -1 -1  1 -1 -1  1  1\n102  1 -1  1 -1 -1  1  1\n103 -1  1  1 -1 -1  1  1\n104  1  1  1 -1 -1  1  1\n105 -1 -1 -1  1 -1  1  1\n106  1 -1 -1  1 -1  1  1\n107 -1  1 -1  1 -1  1  1\n108  1  1 -1  1 -1  1  1\n109 -1 -1  1  1 -1  1  1\n110  1 -1  1  1 -1  1  1\n111 -1  1  1  1 -1  1  1\n112  1  1  1  1 -1  1  1\n113 -1 -1 -1 -1  1  1  1\n114  1 -1 -1 -1  1  1  1\n115 -1  1 -1 -1  1  1  1\n116  1  1 -1 -1  1  1  1\n117 -1 -1  1 -1  1  1  1\n118  1 -1  1 -1  1  1  1\n119 -1  1  1 -1  1  1  1\n120  1  1  1 -1  1  1  1\n121 -1 -1 -1  1  1  1  1\n122  1 -1 -1  1  1  1  1\n123 -1  1 -1  1  1  1  1\n124  1  1 -1  1  1  1  1\n125 -1 -1  1  1  1  1  1\n126  1 -1  1  1  1  1  1\n127 -1  1  1  1  1  1  1\n128  1  1  1  1  1  1  1\n\nThis can be an input to specify the design using another function, say with optFederov which uses Federov’s exchange algorithm to generate the design.\n\n\ndesF <- optFederov(~ .^2, \n                   data = dat,\n                   nTrials = 32,\n                   nRepeats = 100)\ndesF\n\n\n$D\n[1] 0.8867999\n\n$A\n[1] 1.296784\n\n$Ge\n[1] 0.412\n\n$Dea\n[1] 0.241\n\n$design\n    X1 X2 X3 X4 X5 X6 X7\n4    1  1 -1 -1 -1 -1 -1\n5   -1 -1  1 -1 -1 -1 -1\n10   1 -1 -1  1 -1 -1 -1\n11  -1  1 -1  1 -1 -1 -1\n16   1  1  1  1 -1 -1 -1\n17  -1 -1 -1 -1  1 -1 -1\n23  -1  1  1 -1  1 -1 -1\n28   1  1 -1  1  1 -1 -1\n30   1 -1  1  1  1 -1 -1\n33  -1 -1 -1 -1 -1  1 -1\n38   1 -1  1 -1 -1  1 -1\n44   1  1 -1  1 -1  1 -1\n50   1 -1 -1 -1  1  1 -1\n51  -1  1 -1 -1  1  1 -1\n56   1  1  1 -1  1  1 -1\n61  -1 -1  1  1  1  1 -1\n66   1 -1 -1 -1 -1 -1  1\n67  -1  1 -1 -1 -1 -1  1\n72   1  1  1 -1 -1 -1  1\n76   1  1 -1  1 -1 -1  1\n77  -1 -1  1  1 -1 -1  1\n84   1  1 -1 -1  1 -1  1\n86   1 -1  1 -1  1 -1  1\n90   1 -1 -1  1  1 -1  1\n95  -1  1  1  1  1 -1  1\n100  1  1 -1 -1 -1  1  1\n105 -1 -1 -1  1 -1  1  1\n110  1 -1  1  1 -1  1  1\n111 -1  1  1  1 -1  1  1\n117 -1 -1  1 -1  1  1  1\n123 -1  1 -1  1  1  1  1\n128  1  1  1  1  1  1  1\n\n$rows\n [1]   4   5  10  11  16  17  23  28  30  33  38  44  50  51  56  61\n[17]  66  67  72  76  77  84  86  90  95 100 105 110 111 117 123 128\n\nIf you want to further randomise within blocks, you can pass the above result to optBlock.\n\n\ndesFBlk <- optBlock(~ .^2, \n                    withinData = desF$design,\n                    blocksizes = rep(8, 4),\n                    nRepeats = 20)\n\ndesFBlk\n\n\n$D\n[1] 0.8049815\n\n$diagonality\n[1] 0.836\n\n$Blocks\n$Blocks$B1\n    X1 X2 X3 X4 X5 X6 X7\n4    1  1 -1 -1 -1 -1 -1\n17  -1 -1 -1 -1  1 -1 -1\n23  -1  1  1 -1  1 -1 -1\n33  -1 -1 -1 -1 -1  1 -1\n77  -1 -1  1  1 -1 -1  1\n84   1  1 -1 -1  1 -1  1\n90   1 -1 -1  1  1 -1  1\n123 -1  1 -1  1  1  1  1\n\n$Blocks$B2\n    X1 X2 X3 X4 X5 X6 X7\n10   1 -1 -1  1 -1 -1 -1\n16   1  1  1  1 -1 -1 -1\n28   1  1 -1  1  1 -1 -1\n50   1 -1 -1 -1  1  1 -1\n61  -1 -1  1  1  1  1 -1\n67  -1  1 -1 -1 -1 -1  1\n86   1 -1  1 -1  1 -1  1\n100  1  1 -1 -1 -1  1  1\n\n$Blocks$B3\n    X1 X2 X3 X4 X5 X6 X7\n5   -1 -1  1 -1 -1 -1 -1\n11  -1  1 -1  1 -1 -1 -1\n30   1 -1  1  1  1 -1 -1\n44   1  1 -1  1 -1  1 -1\n56   1  1  1 -1  1  1 -1\n66   1 -1 -1 -1 -1 -1  1\n95  -1  1  1  1  1 -1  1\n110  1 -1  1  1 -1  1  1\n\n$Blocks$B4\n    X1 X2 X3 X4 X5 X6 X7\n38   1 -1  1 -1 -1  1 -1\n51  -1  1 -1 -1  1  1 -1\n72   1  1  1 -1 -1 -1  1\n76   1  1 -1  1 -1 -1  1\n105 -1 -1 -1  1 -1  1  1\n111 -1  1  1  1 -1  1  1\n117 -1 -1  1 -1  1  1  1\n128  1  1  1  1  1  1  1\n\n\n$design\n    X1 X2 X3 X4 X5 X6 X7\n4    1  1 -1 -1 -1 -1 -1\n17  -1 -1 -1 -1  1 -1 -1\n23  -1  1  1 -1  1 -1 -1\n33  -1 -1 -1 -1 -1  1 -1\n77  -1 -1  1  1 -1 -1  1\n84   1  1 -1 -1  1 -1  1\n90   1 -1 -1  1  1 -1  1\n123 -1  1 -1  1  1  1  1\n10   1 -1 -1  1 -1 -1 -1\n16   1  1  1  1 -1 -1 -1\n28   1  1 -1  1  1 -1 -1\n50   1 -1 -1 -1  1  1 -1\n61  -1 -1  1  1  1  1 -1\n67  -1  1 -1 -1 -1 -1  1\n86   1 -1  1 -1  1 -1  1\n100  1  1 -1 -1 -1  1  1\n5   -1 -1  1 -1 -1 -1 -1\n11  -1  1 -1  1 -1 -1 -1\n30   1 -1  1  1  1 -1 -1\n44   1  1 -1  1 -1  1 -1\n56   1  1  1 -1  1  1 -1\n66   1 -1 -1 -1 -1 -1  1\n95  -1  1  1  1  1 -1  1\n110  1 -1  1  1 -1  1  1\n38   1 -1  1 -1 -1  1 -1\n51  -1  1 -1 -1  1  1 -1\n72   1  1  1 -1 -1 -1  1\n76   1  1 -1  1 -1 -1  1\n105 -1 -1 -1  1 -1  1  1\n111 -1  1  1  1 -1  1  1\n117 -1 -1  1 -1  1  1  1\n128  1  1  1  1  1  1  1\n\n$rows\n [1]   4  17  23  33  77  84  90 123  10  16  28  50  61  67  86 100\n[17]   5  11  30  44  56  66  95 110  38  51  72  76 105 111 117 128\n\nagricolae\nagricolae is motivated by agricultural applications although the designs are applicable across a variety of fields.\n\n\nlibrary(agricolae)\n\n\n\nThe functions to create the design all begin with the word “design.” and the names of the functions are remnant of the name of the experimental design. E.g. design.rcbd generates a Randomised Complete Block Design and design.split generates a Split Plot Design.\n\n\nls(\"package:agricolae\") %>% \n  str_subset(\"^design.\")\n\n\n [1] \"design.ab\"      \"design.alpha\"   \"design.bib\"    \n [4] \"design.crd\"     \"design.cyclic\"  \"design.dau\"    \n [7] \"design.graeco\"  \"design.lattice\" \"design.lsd\"    \n[10] \"design.mat\"     \"design.rcbd\"    \"design.split\"  \n[13] \"design.strip\"   \"design.youden\" \n\nRather than going through each of the functions, I’ll just show one. The command below generates a balanced incomplete block design with 7 treatments of block size 3. This the same design structure as the first example for AlgDesign. What do you think of the input and output?\n\n\ntrt <- LETTERS[1:7]\ndesign.bib(trt = trt, k = 3)\n\n\n\nParameters BIB\n==============\nLambda     : 1\ntreatmeans : 7\nBlock size : 3\nBlocks     : 7\nReplication: 3 \n\nEfficiency factor 0.7777778 \n\n<<< Book >>>\n$parameters\n$parameters$design\n[1] \"bib\"\n\n$parameters$trt\n[1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\"\n\n$parameters$k\n[1] 3\n\n$parameters$serie\n[1] 2\n\n$parameters$seed\n[1] 1804898417\n\n$parameters$kinds\n[1] \"Super-Duper\"\n\n\n$statistics\n       lambda treatmeans blockSize blocks r Efficiency\nvalues      1          7         3      7 3  0.7777778\n\n$sketch\n     [,1] [,2] [,3]\n[1,] \"C\"  \"B\"  \"D\" \n[2,] \"A\"  \"E\"  \"B\" \n[3,] \"F\"  \"B\"  \"G\" \n[4,] \"G\"  \"C\"  \"E\" \n[5,] \"G\"  \"A\"  \"D\" \n[6,] \"A\"  \"F\"  \"C\" \n[7,] \"F\"  \"E\"  \"D\" \n\n$book\n   plots block trt\n1    101     1   C\n2    102     1   B\n3    103     1   D\n4    201     2   A\n5    202     2   E\n6    203     2   B\n7    301     3   F\n8    302     3   B\n9    303     3   G\n10   401     4   G\n11   402     4   C\n12   403     4   E\n13   501     5   G\n14   502     5   A\n15   503     5   D\n16   601     6   A\n17   602     6   F\n18   603     6   C\n19   701     7   F\n20   702     7   E\n21   703     7   D\n\nMore examples are given in the agricolae tutorial.\nlhs\nThe lhs package is completely different to the previous two packages. It implements methods for creating and augmenting Latin Hypercube Samples and Orthogonal Array Latin Hypercube Samples. The treatment variables here are the parameters and are continuous. In the example below, there are 10 parameters were 30 samples will be drawn from.\n\n\nlibrary(lhs)\n# a design with 30 samples from 10 parameters\nA <- randomLHS(30, 10)\nA\n\n\n            [,1]       [,2]       [,3]       [,4]        [,5]\n [1,] 0.85115160 0.80153721 0.26562089 0.24240381 0.386617133\n [2,] 0.03162770 0.11851068 0.20750833 0.22137816 0.737580563\n [3,] 0.94326309 0.99286802 0.55167951 0.04431126 0.073908842\n [4,] 0.15341898 0.23664814 0.45088836 0.02736497 0.276594703\n [5,] 0.53987796 0.69129259 0.61068716 0.68112190 0.840092421\n [6,] 0.34338962 0.91067411 0.50772141 0.46340514 0.543650700\n [7,] 0.87984431 0.18530938 0.28391957 0.80767211 0.636091307\n [8,] 0.74093451 0.94142899 0.47633881 0.93482745 0.101815507\n [9,] 0.22679294 0.05950478 0.70384589 0.84840308 0.046119869\n[10,] 0.59543890 0.14230001 0.91973016 0.38743743 0.008173053\n[11,] 0.71222052 0.84574251 0.05719443 0.33460392 0.414795358\n[12,] 0.31313954 0.55023270 0.67189798 0.98743475 0.480147544\n[13,] 0.06589897 0.02727366 0.94372045 0.11200430 0.776188787\n[14,] 0.67856942 0.64694630 0.11695731 0.57667893 0.576669680\n[15,] 0.60779222 0.47346774 0.57803451 0.77359785 0.686925390\n[16,] 0.77869112 0.45967726 0.97082607 0.72001527 0.158727598\n[17,] 0.47753672 0.33965295 0.34264293 0.88078583 0.932636317\n[18,] 0.24829930 0.28054142 0.82863690 0.48987801 0.831406425\n[19,] 0.63438918 0.62665931 0.19339855 0.63126047 0.222550404\n[20,] 0.42615936 0.78697269 0.31122846 0.54731724 0.618925200\n[21,] 0.98558294 0.31283813 0.79937608 0.09708168 0.974254219\n[22,] 0.82272308 0.72620385 0.63409490 0.51439160 0.888309555\n[23,] 0.28216288 0.40678670 0.00747647 0.15786391 0.462001814\n[24,] 0.44293885 0.88759165 0.87593133 0.17614748 0.301809115\n[25,] 0.91903885 0.58769320 0.85344414 0.73340894 0.261399107\n[26,] 0.39749211 0.21531852 0.40155710 0.40795272 0.175926862\n[27,] 0.53326444 0.09494134 0.36906730 0.28462433 0.521423827\n[28,] 0.12780125 0.76041647 0.14450865 0.32753635 0.958334555\n[29,] 0.19956924 0.39260007 0.76646006 0.65147638 0.353769748\n[30,] 0.09115621 0.53145384 0.09544316 0.91317843 0.722981039\n            [,6]       [,7]       [,8]       [,9]      [,10]\n [1,] 0.57523291 0.64829514 0.30957145 0.56063376 0.58060694\n [2,] 0.37572590 0.09386871 0.09460784 0.62699580 0.07496677\n [3,] 0.33729208 0.14971910 0.02306924 0.12609065 0.18310414\n [4,] 0.77521524 0.27273750 0.43275425 0.84548534 0.13991032\n [5,] 0.18545904 0.57024842 0.83876578 0.94430739 0.55675175\n [6,] 0.04848456 0.68468958 0.93462688 0.69388363 0.77296080\n [7,] 0.40499358 0.22736413 0.49914901 0.63951785 0.29475412\n [8,] 0.83195048 0.86262149 0.90864828 0.71549074 0.95154810\n [9,] 0.20549016 0.82450164 0.34137614 0.35590469 0.33383492\n[10,] 0.11180544 0.99755568 0.77506400 0.90850387 0.04070513\n[11,] 0.71230339 0.51386141 0.51188486 0.74575618 0.47042600\n[12,] 0.14900939 0.62716610 0.60853776 0.19349115 0.85808318\n[13,] 0.31845634 0.36810057 0.68906398 0.48416759 0.10075997\n[14,] 0.68236586 0.46367072 0.53735362 0.97946521 0.53084746\n[15,] 0.46043188 0.79151449 0.39841726 0.16295411 0.32738380\n[16,] 0.52748006 0.73055037 0.10636268 0.45184454 0.60852297\n[17,] 0.08469157 0.11492100 0.64512714 0.26197028 0.87144705\n[18,] 0.28007202 0.90350371 0.27696270 0.41905694 0.25261507\n[19,] 0.84219677 0.41560144 0.73423244 0.01653787 0.01640204\n[20,] 0.98370876 0.54984313 0.26617569 0.32944947 0.20285318\n[21,] 0.48614679 0.73515250 0.59964083 0.87721937 0.82147435\n[22,] 0.94892286 0.89461948 0.05944528 0.27581653 0.97355201\n[23,] 0.89070787 0.95209334 0.17557806 0.57880924 0.65490041\n[24,] 0.03273681 0.35714952 0.82135876 0.80705301 0.91792197\n[25,] 0.65831637 0.31657015 0.44139011 0.39117389 0.72964052\n[26,] 0.54073941 0.03568867 0.88231315 0.53096409 0.45227701\n[27,] 0.62613184 0.18195056 0.23326926 0.79716759 0.42737304\n[28,] 0.25256769 0.48629095 0.72335715 0.07429013 0.67936824\n[29,] 0.90342254 0.03184096 0.15672156 0.06023826 0.73960757\n[30,] 0.74109078 0.23509647 0.98392432 0.20423196 0.38968498\n\nlhs provides a number of methods to find the optimal design each with their own criteria.\n\n\nA1 <- optimumLHS(30, 10, maxSweeps = 4, eps = 0.01)\nA2 <- maximinLHS(30, 10, dup = 5)\nA3 <- improvedLHS(30, 10, dup = 5)\nA4 <- geneticLHS(30, 10, pop = 1000, gen = 8, pMut = 0.1, criterium = \"S\")\nA5 <- geneticLHS(30, 10, pop = 1000, gen = 8, pMut = 0.1, criterium = \"Maximin\")\n\n\n\nez\nThis is mainly focussed on the analysis of experimental data but some functions such as ezDesign is useful for viewing the experimental structure.\n\n\nlibrary(ez)\ndata(ANT2)\nezPrecis(ANT2)\n\n\nData frame dimensions: 5760 rows, 10 columns\n             type missing values      min         max\nsubnum    numeric       0     20        1          20\ngroup      factor       0      2  Control   Treatment\nblock     numeric       0      6        1           6\ntrial      factor       0     48        1          48\ncue        factor       0      4     None     Spatial\nflank      factor       0      3  Neutral Incongruent\nlocation   factor       0      2     down          up\ndirection  factor       0      2     left       right\nrt        numeric     144   5617 179.5972    657.6986\nerror     numeric     144      3        0           1\n\n\n\nezDesign(data = ANT2,\n         x = trial, \n         y = subnum,\n         row = block, \n         col = group)\n\n\n\n\nDoE.base\nDoE.base provides utility functions for the special class design and as seen in Figure 1, DoE.base is used by four other DoE packages that is maintained also by Prof. Dr. Ulrike Grömping.\nDoE.base contains functions to generate factorial designs easily.\n\n\nlibrary(DoE.base)\nfac.design(nlevels = c(2, 2, 3, 3, 6), \n           blocks = 6)\n\n\n   run.no run.no.std.rp Blocks A B C D E\n1       1        29.1.5      1 1 1 2 3 1\n2       2       89.1.15      1 1 1 2 2 3\n3       3      180.1.30      1 2 2 3 3 5\n4       4         4.1.2      1 2 2 1 1 1\n5       5       84.1.14      1 2 2 3 1 3\n6       6      160.1.28      1 2 2 1 2 5\n7       7      118.1.19      1 2 1 3 1 4\n8       8      186.1.31      1 2 1 2 1 6\n9       9       97.1.17      1 1 1 1 3 3\n10     10       92.1.16      1 2 2 2 2 3\n11     11      214.1.35      1 2 1 3 3 6\n12     12      194.1.33      1 2 1 1 2 6\n13     13        39.1.8      1 1 2 1 1 2\n14     14         1.1.1      1 1 1 1 1 1\n15     15      119.1.20      1 1 2 3 1 4\n16     16      127.1.22      1 1 2 2 2 4\n17     17      134.1.23      1 2 1 1 3 4\n18     18        58.1.9      1 2 1 3 2 2\n19     19      135.1.24      1 1 2 1 3 4\n20     20      149.1.25      1 1 1 2 1 5\n21     21       59.1.10      1 1 2 3 2 2\n22     22        38.1.7      1 2 1 1 1 2\n23     23       67.1.12      1 1 2 2 3 2\n24     24      195.1.34      1 1 2 1 2 6\n25     25        32.1.6      1 2 2 2 3 1\n26     26       66.1.11      1 2 1 2 3 2\n27     27      152.1.26      1 2 2 2 1 5\n28     28        21.1.3      1 1 1 3 2 1\n29     29      157.1.27      1 1 1 1 2 5\n30     30      215.1.36      1 1 2 3 3 6\n31     31      100.1.18      1 2 2 1 3 3\n32     32      187.1.32      1 1 2 2 1 6\n33     33      177.1.29      1 1 1 3 3 5\n34     34      126.1.21      1 2 1 2 2 4\n35     35       81.1.13      1 1 1 3 1 3\n36     36        24.1.4      1 2 2 3 2 1\n   run.no run.no.std.rp Blocks A B C D E\n37     37        16.2.4      2 2 2 1 2 1\n38     38      169.2.29      2 1 1 1 3 5\n39     39        43.2.8      2 1 2 2 1 2\n40     40      199.2.34      2 1 2 2 2 6\n41     41      104.2.18      2 2 2 2 3 3\n42     42      206.2.35      2 2 1 1 3 6\n43     43      131.2.22      2 1 2 3 2 4\n44     44      138.2.23      2 2 1 2 3 4\n45     45      172.2.30      2 2 2 1 3 5\n46     46      110.2.19      2 2 1 1 1 4\n47     47      161.2.27      2 1 1 2 2 5\n48     48         5.2.1      2 1 1 2 1 1\n49     49        42.2.7      2 2 1 2 1 2\n50     50       73.2.13      2 1 1 1 1 3\n51     51      191.2.32      2 1 2 3 1 6\n52     52       93.2.15      2 1 1 3 2 3\n53     53      156.2.26      2 2 2 3 1 5\n54     54       96.2.16      2 2 2 3 2 3\n55     55       51.2.10      2 1 2 1 2 2\n56     56      101.2.17      2 1 1 2 3 3\n57     57        13.2.3      2 1 1 1 2 1\n58     58      111.2.20      2 1 2 1 1 4\n59     59      130.2.21      2 2 1 3 2 4\n60     60       76.2.14      2 2 2 1 1 3\n61     61      198.2.33      2 2 1 2 2 6\n62     62      190.2.31      2 2 1 3 1 6\n63     63        33.2.5      2 1 1 3 3 1\n64     64      153.2.25      2 1 1 3 1 5\n65     65      164.2.28      2 2 2 2 2 5\n66     66        50.2.9      2 2 1 1 2 2\n67     67      207.2.36      2 1 2 1 3 6\n68     68       71.2.12      2 1 2 3 3 2\n69     69        36.2.6      2 2 2 3 3 1\n70     70         8.2.2      2 2 2 2 1 1\n71     71       70.2.11      2 2 1 3 3 2\n72     72      139.2.24      2 1 2 2 3 4\n    run.no run.no.std.rp Blocks A B C D E\n73      73       85.3.15      3 1 1 1 2 3\n74      74      105.3.17      3 1 1 3 3 3\n75      75        17.3.3      3 1 1 2 2 1\n76      76      211.3.36      3 1 2 2 3 6\n77      77      114.3.19      3 2 1 2 1 4\n78      78        47.3.8      3 1 2 3 1 2\n79      79       55.3.10      3 1 2 2 2 2\n80      80      182.3.31      3 2 1 1 1 6\n81      81      168.3.28      3 2 2 3 2 5\n82      82      165.3.27      3 1 1 3 2 5\n83      83      142.3.23      3 2 1 3 3 4\n84      84      145.3.25      3 1 1 1 1 5\n85      85       62.3.11      3 2 1 1 3 2\n86      86      148.3.26      3 2 2 1 1 5\n87      87      108.3.18      3 2 2 3 3 3\n88      88        25.3.5      3 1 1 1 3 1\n89      89         9.3.1      3 1 1 3 1 1\n90      90       77.3.13      3 1 1 2 1 3\n91      91      122.3.21      3 2 1 1 2 4\n92      92        12.3.2      3 2 2 3 1 1\n93      93        46.3.7      3 2 1 3 1 2\n94      94       88.3.16      3 2 2 1 2 3\n95      95        20.3.4      3 2 2 2 2 1\n96      96        54.3.9      3 2 1 2 2 2\n97      97      203.3.34      3 1 2 3 2 6\n98      98       80.3.14      3 2 2 2 1 3\n99      99      123.3.22      3 1 2 1 2 4\n100    100      173.3.29      3 1 1 2 3 5\n101    101        28.3.6      3 2 2 1 3 1\n102    102      176.3.30      3 2 2 2 3 5\n103    103      202.3.33      3 2 1 3 2 6\n104    104      115.3.20      3 1 2 2 1 4\n105    105      210.3.35      3 2 1 2 3 6\n106    106      183.3.32      3 1 2 1 1 6\n107    107       63.3.12      3 1 2 1 3 2\n108    108      143.3.24      3 1 2 3 3 4\n    run.no run.no.std.rp Blocks A B C D E\n109    109      179.4.30      4 1 2 3 3 5\n110    110      151.4.26      4 1 2 2 1 5\n111    111       60.4.10      4 2 2 3 2 2\n112    112        31.4.6      4 1 2 2 3 1\n113    113         3.4.2      4 1 2 1 1 1\n114    114        22.4.3      4 2 1 3 2 1\n115    115       99.4.18      4 1 2 1 3 3\n116    116        30.4.5      4 2 1 2 3 1\n117    117       68.4.12      4 2 2 2 3 2\n118    118      196.4.34      4 2 2 1 2 6\n119    119       90.4.15      4 2 1 2 2 3\n120    120        57.4.9      4 1 1 3 2 2\n121    121      158.4.27      4 2 1 1 2 5\n122    122      193.4.33      4 1 1 1 2 6\n123    123      136.4.24      4 2 2 1 3 4\n124    124       82.4.13      4 2 1 3 1 3\n125    125       65.4.11      4 1 1 2 3 2\n126    126        37.4.7      4 1 1 1 1 2\n127    127      120.4.20      4 2 2 3 1 4\n128    128      178.4.29      4 2 1 3 3 5\n129    129      128.4.22      4 2 2 2 2 4\n130    130      188.4.32      4 2 2 2 1 6\n131    131         2.4.1      4 2 1 1 1 1\n132    132       91.4.16      4 1 2 2 2 3\n133    133      185.4.31      4 1 1 2 1 6\n134    134      159.4.28      4 1 2 1 2 5\n135    135       98.4.17      4 2 1 1 3 3\n136    136        40.4.8      4 2 2 1 1 2\n137    137      150.4.25      4 2 1 2 1 5\n138    138      125.4.21      4 1 1 2 2 4\n139    139       83.4.14      4 1 2 3 1 3\n140    140      133.4.23      4 1 1 1 3 4\n141    141        23.4.4      4 1 2 3 2 1\n142    142      117.4.19      4 1 1 3 1 4\n143    143      216.4.36      4 2 2 3 3 6\n144    144      213.4.35      4 1 1 3 3 6\n    run.no run.no.std.rp Blocks A B C D E\n145    145      171.5.30      5 1 2 1 3 5\n146    146      102.5.17      5 2 1 2 3 3\n147    147      162.5.27      5 2 1 2 2 5\n148    148      112.5.20      5 2 2 1 1 4\n149    149      154.5.25      5 2 1 3 1 5\n150    150       74.5.13      5 2 1 1 1 3\n151    151      163.5.28      5 1 2 2 2 5\n152    152        15.5.4      5 1 2 1 2 1\n153    153       72.5.12      5 2 2 3 3 2\n154    154       95.5.16      5 1 2 3 2 3\n155    155      205.5.35      5 1 1 1 3 6\n156    156        35.5.6      5 1 2 3 3 1\n157    157         7.5.2      5 1 2 2 1 1\n158    158      129.5.21      5 1 1 3 2 4\n159    159         6.5.1      5 2 1 2 1 1\n160    160       75.5.14      5 1 2 1 1 3\n161    161      208.5.36      5 2 2 1 3 6\n162    162        14.5.3      5 2 1 1 2 1\n163    163       94.5.15      5 2 1 3 2 3\n164    164      132.5.22      5 2 2 3 2 4\n165    165        34.5.5      5 2 1 3 3 1\n166    166       69.5.11      5 1 1 3 3 2\n167    167      170.5.29      5 2 1 1 3 5\n168    168      137.5.23      5 1 1 2 3 4\n169    169       52.5.10      5 2 2 1 2 2\n170    170      155.5.26      5 1 2 3 1 5\n171    171        49.5.9      5 1 1 1 2 2\n172    172      200.5.34      5 2 2 2 2 6\n173    173        41.5.7      5 1 1 2 1 2\n174    174      192.5.32      5 2 2 3 1 6\n175    175        44.5.8      5 2 2 2 1 2\n176    176      140.5.24      5 2 2 2 3 4\n177    177      197.5.33      5 1 1 2 2 6\n178    178      109.5.19      5 1 1 1 1 4\n179    179      103.5.18      5 1 2 2 3 3\n180    180      189.5.31      5 1 1 3 1 6\n    run.no run.no.std.rp Blocks A B C D E\n181    181      106.6.17      6 2 1 3 3 3\n182    182      146.6.25      6 2 1 1 1 5\n183    183       79.6.14      6 1 2 2 1 3\n184    184        53.6.9      6 1 1 2 2 2\n185    185      209.6.35      6 1 1 2 3 6\n186    186       64.6.12      6 2 2 1 3 2\n187    187      166.6.27      6 2 1 3 2 5\n188    188        19.6.4      6 1 2 2 2 1\n189    189      204.6.34      6 2 2 3 2 6\n190    190        26.6.5      6 2 1 1 3 1\n191    191       78.6.13      6 2 1 2 1 3\n192    192       56.6.10      6 2 2 2 2 2\n193    193      181.6.31      6 1 1 1 1 6\n194    194      174.6.29      6 2 1 2 3 5\n195    195       87.6.16      6 1 2 1 2 3\n196    196        10.6.1      6 2 1 3 1 1\n197    197      212.6.36      6 2 2 2 3 6\n198    198      147.6.26      6 1 2 1 1 5\n199    199      107.6.18      6 1 2 3 3 3\n200    200        48.6.8      6 2 2 3 1 2\n201    201      116.6.20      6 2 2 2 1 4\n202    202       86.6.15      6 2 1 1 2 3\n203    203      184.6.32      6 2 2 1 1 6\n204    204        27.6.6      6 1 2 1 3 1\n205    205      124.6.22      6 2 2 1 2 4\n206    206      141.6.23      6 1 1 3 3 4\n207    207      201.6.33      6 1 1 3 2 6\n208    208        18.6.3      6 2 1 2 2 1\n209    209        45.6.7      6 1 1 3 1 2\n210    210      113.6.19      6 1 1 2 1 4\n211    211      167.6.28      6 1 2 3 2 5\n212    212      121.6.21      6 1 1 1 2 4\n213    213      144.6.24      6 2 2 3 3 4\n214    214       61.6.11      6 1 1 1 3 2\n215    215      175.6.30      6 1 2 2 3 5\n216    216        11.6.2      6 1 2 3 1 1\nclass=design, type= full factorial.blocked \nNOTE: columns run.no and run.no.std.rp  are annotation, \n not part of the data frame\n\nIt also contains functions to create orthogonal array designs.\n\n\ndes <- oa.design(nlevels = c(rep(2, 8), 8))\ndes\n\n\n   A B C D E F G H J\n1  1 2 1 2 2 1 2 1 6\n2  2 1 2 1 2 1 2 1 2\n3  2 1 1 2 2 1 1 2 4\n4  2 2 1 1 2 2 1 1 3\n5  1 1 1 1 2 2 2 2 5\n6  1 1 2 2 2 2 1 1 7\n7  1 2 1 2 1 2 1 2 2\n8  1 1 1 1 1 1 1 1 1\n9  1 2 2 1 2 1 1 2 8\n10 1 1 2 2 1 1 2 2 3\n11 2 1 2 1 1 2 1 2 6\n12 2 1 1 2 1 2 2 1 8\n13 2 2 2 2 1 1 1 1 5\n14 2 2 1 1 1 1 2 2 7\n15 1 2 2 1 1 2 2 1 4\n16 2 2 2 2 2 2 2 2 1\nclass=design, type= oa \n\nIf you need to further randomise within a specified block, you can do this using rerandomize.design.\n\n\nrerandomize.design(des, block = \"J\")\n\n\n  run.no run.no.std.rp J A B C D E F G H\n1      1         4.7.1 7 1 1 2 2 2 2 1 1\n2      2        13.7.2 7 2 2 1 1 1 1 2 2\n  run.no run.no.std.rp J A B C D E F G H\n3      3         7.4.1 4 1 2 2 1 1 2 2 1\n4      4        10.4.2 4 2 1 1 2 2 1 1 2\n  run.no run.no.std.rp J A B C D E F G H\n5      5        12.2.2 2 2 1 2 1 2 1 2 1\n6      6         5.2.1 2 1 2 1 2 1 2 1 2\n  run.no run.no.std.rp J A B C D E F G H\n7      7        11.6.2 6 2 1 2 1 1 2 1 2\n8      8         6.6.1 6 1 2 1 2 2 1 2 1\n   run.no run.no.std.rp J A B C D E F G H\n9       9         9.8.2 8 2 1 1 2 1 2 2 1\n10     10         8.8.1 8 1 2 2 1 2 1 1 2\n   run.no run.no.std.rp J A B C D E F G H\n11     11         3.3.1 3 1 1 2 2 1 1 2 2\n12     12        14.3.2 3 2 2 1 1 2 2 1 1\n   run.no run.no.std.rp J A B C D E F G H\n13     13        16.1.2 1 2 2 2 2 2 2 2 2\n14     14         1.1.1 1 1 1 1 1 1 1 1 1\n   run.no run.no.std.rp J A B C D E F G H\n15     15         2.5.1 5 1 1 1 1 2 2 2 2\n16     16        15.5.2 5 2 2 2 2 1 1 1 1\nclass=design, type= oa.blocked \nNOTE: columns run.no and run.no.std.rp  are annotation, \n not part of the data frame\n\nSo those were the top 5 DoE packages. The API of the packages are quite distinct. The object that it outputs can vary from a matrix to a list. DoE might be a dull area for many but it’s quite important for the downstream analysis. Perhaps if many of us talk more about it, it may help invigorate the area!\n\n\n\n\n\nCarnell, Rob. 2020. Lhs: Latin Hypercube Samples. https://CRAN.R-project.org/package=lhs.\n\n\nChatfield, C. 1985. “The Initial Examination of Data.” Journal of the Royal Statistical Society. Series A 148 (3): 214–53.\n\n\nde Mendiburu, Felipe. 2020. Agricolae: Statistical Procedures for Agricultural Research. https://CRAN.R-project.org/package=agricolae.\n\n\nGrömping, Ulrike. 2018. “R Package DoE.base for Factorial Experiments.” Journal of Statistical Software 85 (5): 1–41. https://doi.org/10.18637/jss.v085.i05.\n\n\nLawrence, Michael A. 2016. Ez: Easy Analysis and Visualization of Factorial Experiments. https://CRAN.R-project.org/package=ez.\n\n\nMorgan-Wall, Tyler. 2017. Adjustedcranlogs: Remove Automated and Repeated Downloads from ’Rstudio’ ’Cran’ Download Logs. https://CRAN.R-project.org/package=adjustedcranlogs.\n\n\nWheeler, Bob. 2019. AlgDesign: Algorithmic Experimental Design. https://CRAN.R-project.org/package=AlgDesign.\n\n\nAt least from my teaching experience, statistics subjects are primary about the analysis and most research grants I’ve seen are about an analytical method. The analytical focus is reflected also in the R packages; there are 1,779 R-packages on CRAN with the word “analysis” in the title as opposed to 257 R-packages with the word “design” in its title.↩︎\nKeeping in mind though that your analysis plan may change once you actually have collected data. This is quite common in the analysis of plant breeding trials since some spatial variation only become apparent only after the data collection.↩︎\nI originally had a webscrapping error where I didn’t remove duplicate entries so numbers presented at TokyoR and SSA Webinar had the wrong numbers.↩︎\nAs of 2021-02-07.↩︎\n",
    "preview": "posts/2021-02-03-current-state-of-experimental-design-r-packages/figures/download-timeplot-1.png",
    "last_modified": "2024-04-07T11:55:28+08:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 1344
  },
  {
    "path": "posts/2022-02-04-buildblock/",
    "title": "Build block data clean",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Jixing Liu",
        "url": "https://jixing475.github.io/jixingBlog"
      }
    ],
    "date": "2021-02-03",
    "categories": [
      "experimental design",
      "R"
    ],
    "contents": "\n\nContents\nACEMOL\n\n\n\n\nlibrary(tidyverse)\ndata_path_ACEMOL <- here::here(\"analysis/data/raw_data/Build_block_ACEMOL.csv\")\n\n\n\n\nACEMOL\n\n\n\ndf <- read_csv(data_path_ACEMOL)\n\ndf %>% head()\n\n\n#> # A tibble: 6 × 9\n#>   标题   标题链接  CatalogNo. CasNo. Name  ReaxyNo. CNName `cards-box`\n#>   <chr>  <chr>     <chr>      <chr>  <chr> <chr>    <chr>  <chr>      \n#> 1 >(2S)… http://w… Catalog N… Cas N… >(2S… Reaxy N… CN Na… 216237-52-4\n#> 2 >1-Am… http://w… Catalog N… Cas N… >1-A… Reaxy N… CN Na… 22059-21-8 \n#> 3 >1-(B… http://w… Catalog N… Cas N… >1-(… Reaxy N… CN Na… 88950-64-5 \n#> 4 >Meth… http://w… Catalog N… Cas N… >Met… Reaxy N… CN Na… 72784-43-1 \n#> 5 >Meth… http://w… Catalog N… Cas N… >Met… Reaxy N… CN Na… 72784-42-0 \n#> 6 >ethy… http://w… Catalog N… Cas N… >eth… Reaxy N… CN Na… 42303-42-4 \n#> # … with 1 more variable: cards-box-desc1 <chr>\n\ndf %>% colnames()\n\n\n#> [1] \"标题\"            \"标题链接\"        \"CatalogNo.\"     \n#> [4] \"CasNo.\"          \"Name\"            \"ReaxyNo.\"       \n#> [7] \"CNName\"          \"cards-box\"       \"cards-box-desc1\"\n\n\ndf_clean <- \ndf %>%\n  select(name = Name,\n         name_zh = CNName,\n         SMILES = `cards-box-desc1`) %>%\n  mutate(name_zh = str_remove(name_zh, \"CN Name:\"),\n         name = str_remove(name, \"^>\"))\n\n\n\n\n\n\n\n\n\n\nlibrary(docking)\ndocking::init_py()\n\ndf_clean %>% \n  pull(SMILES) %>% \n  map_chr(~ py$smiles_to_canonical(.x))\n\nis.na(.Last.value) %>% sum()\n\n\n\n# df_clean %>% \n#   py$df_add_ROMol() %>% \n#   rename(ID = name) %>% \n#   open_in_DataWarrior()\n\n\n\n\n\n\n\n",
    "preview": "https://gitee.com/jixing475/tuchuang/raw/master/uPic/image-20210601220146194.png",
    "last_modified": "2024-04-07T11:55:28+08:00",
    "input_file": {}
  }
]
